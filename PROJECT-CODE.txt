#pip install ImageAi==2.0.3
from tkinter import messagebox
from tkinter import *
from tkinter import simpledialog
import tkinter
from tkinter import filedialog
from imutils import paths
import matplotlib.pyplot as plt
import datetime
from tkinter.filedialog import askopenfilename
import cv2 
import shutil
import os
from imageai.Prediction.Custom import CustomImagePrediction
import os
import winsound

main = tkinter.Tk()
main.title("Suspicious Activity Detection")
main.geometry("1200x1200")

global filename

execution_path = os.getcwd()
prediction = CustomImagePrediction()
prediction.setModelTypeAsResNet()
prediction.setModelPath("model.h5")
prediction.setJsonPath("model_class.json")
prediction.loadModel(num_objects=2)
def beep():
    frequency = 2500  # Set Frequency To 2500 Hertz
    duration = 1000  # Set Duration To 1000 ms == 1 second
    winsound.Beep(frequency, duration)
    
def upload():
   global filename
   filename = askopenfilename(initialdir = "videos")
   pathlabel.config(text=filename)

def generateFrame():
   global filename
   text.delete('1.0', END)
   if not os.path.exists('frames'):
      os.mkdir('frames')
   else:
      shutil.rmtree('frames')
      os.mkdir('frames')
   vidObj = cv2.VideoCapture(filename) 
   count = 0
   success = 1
   while success:
      success, image = vidObj.read() 
      if count < 500:
         cv2.imwrite("frames/frame%d.jpg" % count, image)
         text.insert(END,"frames/frame."+str(count)+" saved\n")
         print("frames/frame."+str(count)+" saved")
         #pathlabel.config(text="frames/frame."+str(count)+" saved")
      else:
         break
      count += 1
   pathlabel.config(text="Frame generation process completed. All frames saved inside frame folder")


def detectActivity():
   imagePaths = sorted(list(paths.list_images("frames")))
   count = 0
   option = 0;
   text1.delete('1.0', END)
   for imagePath in imagePaths:
      predictions, probabilities = prediction.predictImage(imagePath, result_count=1)
      for eachPrediction, eachProbability in zip(predictions, probabilities):
         if float(eachProbability) > 80:
            count = count + 1;
         if float(eachProbability) < 80:
            count = 0
         if count > 10:
            option = 1
            beep()
            #print(" is predicted as "+eachPrediction+" with probability : " +str(eachProbability))
            text1.insert(END,imagePath+" is predicted as "+eachPrediction+" with probability : " +str(eachProbability)+"\n\n")
            count = 0;
      print(imagePath+" processed")
   if option == 0:
      text1.insert(END,"No suspicious activity found in given footage")   

font = ('times', 20, 'bold')
title = Label(main, text='Suspicious Activity Detection From CCTV Footage')
title.config(bg='brown', fg='white')  
title.config(font=font)           
title.config(height=3, width=80)       
title.place(x=5,y=5)

font1 = ('times', 14, 'bold')
upload = Button(main, text="Upload CCTV Footage", command=upload)
upload.place(x=50,y=100)
upload.config(font=font1)  

pathlabel = Label(main)
pathlabel.config(bg='brown', fg='white')  
pathlabel.config(font=font1)           
pathlabel.place(x=300,y=100)

depthbutton = Button(main, text="Generate Frames", command=generateFrame)
depthbutton.place(x=50,y=150)
depthbutton.config(font=font1) 

userinterest = Button(main, text="Detect Suspicious Activity Frame", command=detectActivity)
userinterest.place(x=280,y=150)
userinterest.config(font=font1) 

font1 = ('times', 12, 'bold')
text=Text(main,height=25,width=50)
scroll=Scrollbar(text)
text.configure(yscrollcommand=scroll.set)
text.place(x=10,y=200)
text.config(font=font1)

text1=Text(main,height=25,width=50)
scroll=Scrollbar(text1)
text1.configure(yscrollcommand=scroll.set)
text1.place(x=550,y=200)
text1.config(font=font1)


main.config(bg='green')
main.mainloop()
#pip install ImageAi==2.0.3 
from tkinter import messagebox  
from tkinter import *  
from tkinter import simpledialog  
import tkinter from 
tkinter import filedialog  
from imutils import paths  
import matplotlib.pyplot as plt 
import datetime 
from tkinter.filedialog 
import askopenfilename 
import cv2   
import shutil 
import os  
from imageai.Prediction.Custom import CustomImagePrediction 
import os  
import winsound  
main = tkinter.Tk() main.title("Suspicious Activity Detection") main.geometry("1200x1200")  
global filename  
execution_path = os.getcwd()  
prediction = CustomImagePrediction()  
prediction.setModelTypeAsResNet()  
prediction.setModelPath("model.h5")  
prediction.setJsonPath("model_class.json")  
prediction.loadModel(num_objects=2) 
def beep():  
frequency = 2500   
# Set Frequency To 2500 Hertz     duration = 1000  
# Set Duration To 1000 ms == 1 second      
winsound.Beep(frequency, duration)  
def upload():     
global filename    
filename = askopenfilename(initialdir = "videos")    pathlabel.config(text=filename)  
def generateFrame():    global filename    
text.delete('1.0', END)   
if not os.path.exists('frames'):  
os.mkdir('frames')    else:  
shutil.rmtree('frames')   
count = 0    
    os.mkdir('frames') 
success = 1     
while success:  
success, image = vidObj.read()        
if count < 500:  
cv2.imwrite("frames/frame%d.jpg" 
   vidObj = cv2.VideoCapture(filename)     
% 
text.insert(END,"frames/frame."+str(count)+" saved\n")         
print("frames/frame."+str(count)+" saved")  
#pathlabel.config(text="frames/frame."+str(count)+" saved")      
else:  
break    
count, 
image)          
   count += 1     
pathlabel.config(text="Frame generation process completed. All frames saved inside frame folder")  
def detectActivity():  
imagePaths = sorted(list(paths.list_images("frames")))     
count = 0    option = 0;    text1.delete('1.0', END)    
for imagePath in imagePaths:  
predictions, probabilities = prediction.predictImage(imagePath, result_count=1)       
for eachPrediction, eachProbability in zip(predictions, probabilities):           
if float(eachProbability) > 80:  
count = count + 1;   
       if
 float(eachProbaity) < 80:  
+" is predicted as "+eachPrediction+" with probability : " +str(eachProbability))             
print(imagePathtext1.insert(END,imagePath+" is predicted as "+eachPrediction+" with   
probability : " +str(eachProbability)+"\n\n")           
count = 0;  
print(imagePath+" processed")   
if option == 0:  
text1.insert(END,"No suspicious activity found in given footage")     
font = ('times', 20, 'bold') title = Label(main, text='Suspicious Activity Detection From CCTV Footage') 
title.config(bg='brown', fg='white')    
title.config(font=font)             
title.config(height=3, width=80)         
title.place(x=5,y=5)  
font1 = ('times', 14, 'bold')  
upload = Button(main, text="Upload CCTV Footage", command=upload)  
upload.place(x=50,y=100)  
upload.config(font=font1)    
pathlabel = Label(main)  
pathlabel.config(bg='brown', fg='white')    
pathlabel.config(font=font1)             
pathlabel.place(x=300,y=100)  
depthbutton = Button(main, text="Generate Frames", command=generateFrame)  
depthbutton.place(x=50,y=150)  
depthbutton.config(font=font1)   
userinterest = Button(main, text="Detect Suspicious Activity Frame", command=detectActivity)  
userinterest.place(x=280,y=150)  
userinterest.config(font=font1)   
font1 = ('times', 12, 'bold')  
text=Text(main,height=25,width=50)  
scroll=Scrollbar(text)  
text.configure(yscrollcommand=scroll.set)  
text.place(x=10,y=200) 
text.config(font=font1)  
text1=Text(main,height=25,width=50) scroll=Scrollbar(text1)  
text1.configure(yscrollcommand=scroll.set) 
text1.place(x=550,y=200) 
text1.config(font=font1)  
main.config(bg='green') main.mainloop()  
import tensorflow as tf 
from tensorflow.keras import layers, models 
# Define the CNN model architecture 
model = models.Sequential() 
# Convolutional layers 
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(64, (3, 3), activation='relu')) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(64, (3, 3), activation='relu')) 
model.add(layers.Flatten()) 
model.add(layers.Dense(64, activation='relu')) 
model.add(layers.Dense(10, activation='softmax'))  # Assuming 10 classes for classification  
model.compile(optimizer='adam', 
loss='sparse_categorical_crossentropy', 
metrics=['accuracy']) 
model.summary() 
mnist = tf.keras.datasets.mnist 
(x_train, y_train), (x_test, y_test) = mnist.load_data() 
x_train, x_test = x_train / 255.0, x_test / 255.0 
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) 
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1) 
model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test)) 
test_loss, test_acc = model.evaluate(x_test, y_test) 
print('Test accuracy:', test_acc) 
import tensorflow as tf 
from tensorflow.keras import layers, models 
from tensorflow.keras.preprocessing.sequence import pad_sequences 
from tensorflow.keras.preprocessing.image import load_img, img_to_array 
# Define the RNN model architecture for image classification 
model = models.Sequential() 
model.add(layers.LSTM(128, input_shape=(None, 256), return_sequences=True)) 
model.add(layers.TimeDistributed(layers.Dense(10, activation='softmax'))) 
model.compile(optimizer='adam', 
loss='categorical_crossentropy', 
metrics=['accuracy']) 
image_data = []   
image_labels = []   
image_data_array = np.array(image_data) 
image_labels_array = np.array(image_labels) 
image_data_reshaped 
= 
image_data_array.shape[1]) 
image_data_array.reshape(image_data_array.shape[0], 
model.fit(image_data_reshaped, image_labels_array, epochs=10, batch_size=32) 
loss, accuracy = model.evaluate(image_data_reshaped, image_labels_array) 
print('Test loss:', loss) 
print('Test accuracy:', accuracy) 
import numpy as np 
import matplotlib.pyplot as plt 
from tensorflow.keras import layers, models, optimizers 
def build_generator(latent_dim, image_shape): 
generator = models.Sequential() 
1,  
generator.add(layers.Dense(128 * 7 * 7, input_dim=latent_dim)) 
generator.add(layers.Reshape((7, 7, 128))) 
generator.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', 
activation='relu')) 
generator.add(layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', 
activation='relu')) 
generator.add(layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')) 
generator.add(layers.Reshape(image_shape)) 
return generator 
def build_discriminator(image_shape): 
discriminator = models.Sequential() 
discriminator.add(layers.Conv2D(64, kernel_size=3, strides=2, input_shape=image_shape, 
padding='same', activation='relu')) 
discriminator.add(layers.Conv2D(128, 
kernel_size=3, 
activation='relu')) 
discriminator.add(layers.Flatten()) 
discriminator.add(layers.Dense(1, activation='sigmoid')) 
return discriminator 
def build_gan(generator, discriminator): 
discriminator.trainable = False 
gan = models.Sequential([generator, discriminator]) 
gan.compile(loss='binary_crossentropy', 
strides=2, 
padding='same', 
optimizer=optimizers.Adam(lr=0.0002, 
beta_1=0.5)) 
return gan 
latent_dim = 100 
image_shape = (28, 28, 1)  
generator = build_generator(latent_dim, image_shape) 
discriminator = build_discriminator(image_shape) 
gan = build_gan(generator, discriminator) 
from tensorflow.keras.datasets import mnist 
(train_images, _), (_, _) = mnist.load_data() 
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') 
train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1] 
def generate_fake_images(generator, latent_dim, n_samples): 
noise = np.random.normal(0, 1, (n_samples, latent_dim)) 
fake_images = generator.predict(noise) 
return fake_images 
batch_size = 128 
epochs = 10000 
save_interval = 1000 
for epoch in range(epochs): 
# Generate fake images 
fake_images = generate_fake_images(generator, latent_dim, batch_size) 
discriminator_loss_real = discriminator.train_on_batch(train_images[np.random.randint(0, 
train_images.shape[0], batch_size)], np.ones((batch_size, 1))) 
discriminator_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size, 
1))) 
discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake) 
noise = np.random.normal(0, 1, (batch_size, latent_dim)) 
generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))